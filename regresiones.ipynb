{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresiones\n",
    "\n",
    "Aquí vamos a hacer muchas regresiones para ver qué combinación de ingeniería de variables y método de regresión da mejores resultados.\n",
    "\n",
    "El primer paso es establecer una _línea base_ para comparar. Para esto vamos a utilizar una regresión de [Random Forest](https://en.wikipedia.org/wiki/Random_forest) sobre los datos preprocesados diréctamente, sin más. Lo único extra que vamos a hacer es escalar las variables.\n",
    "\n",
    "Hay varias razones para usar Random Forest como baseline, primero es sabido que es un buen método para evitar el _overfitting_ y segundo y más importante en nuestro caso, nos da una estimación de la importancia relativa de las variables, esto puede resultar importante para informar nuestras desiciones más adelante.\n",
    "\n",
    "En general, una regresión tiene un conjunto de _hiperparámetros_ que deben ajustarse para obtener un modelo específico. Este ajuste se hace buscando soluciones en el espacio de hiperparámetros, para evitar ajustar nuestro modelo demasiado (aumentar el sesgo), vamos a usar _cross validation_.\n",
    "\n",
    "Primero vamos a ver cuáles son los hiperparámetros que queremos ajustar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos los datos\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"data/train_preprocesado.csv\")\n",
    "#por alguna razón quedaron dos Na en BsmtCond, así los quitamos pero en realidad hay que regresar a ver qué pasó\n",
    "df_train.dropna(inplace=True)\n",
    "# creamos dataframes para las variables y el objetivo\n",
    "Y = df_train['SalePrice']\n",
    "X = df_train.drop(['SalePrice','Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros por defecto:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 'warn',\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "print('Parámetros por defecto:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators = número de árboles en el bosque\n",
    "- max_features = máximo número de variables a considerar en cada _split_\n",
    "- max_depth = profundidad máxima para cada árbol\n",
    "- min_samples_split = numero mínimo de datos en un nodo antes de un _split_\n",
    "- min_samples_leaf = número mínimo de datos en un nodo\n",
    "- bootstrap = método para muestrear (con o sin reemplazo)\n",
    "\n",
    "Si lo piensa uno, son un montón de parámetros con un montón de valores posibles, entonces tenemos que encontrar alguna forma eficiente de buscar (en el espacio de hiperparámetros). Ahora lo que vamos a hacer es una búsqueda en dos etapas. primero vamos a definir una _malla_ grande de valores y vamos a buscar a azar dentro de esa malla, eso nos va a reducir el espacio de búsqueda, luego vamos a usar ese espacio reducido para utilizar un método más sofisticado (pero más costoso computacionalmente) de búsqueda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Lista ed valores para el número de estimadores\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# máximo número de variables a considerar en cada _split_\n",
    "max_features = ['auto', 'sqrt']\n",
    "# profundidad máxima para cada árbol\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# numero mínimo de datos en un nodo antes de un _split_\n",
    "min_samples_split = [2, 5, 10]\n",
    "# número mínimo de datos en un nodo\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# método para muestrear (con o sin reemplazo)\n",
    "bootstrap = [True, False]\n",
    "# Malla aleatoria\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay exáctamente $2 * 12 * 2 * 3 * 3 * 10 = 4320$ combinaciones de variables en nuestra malla. Por eso no las vamos a probar todas, vamos a buscar aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un modelo vacío\n",
    "rf = RandomForestRegressor()\n",
    "# Búsqueda aleatoria usando 3-fold CV, \n",
    "# Busca sobre 100 iteraciones \n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Ajusta sobre los datos\n",
    "rf_random.fit(X, Y)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahra vamos a ver si la búsqueda aleatoria nos da un mejor modelo que el modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Base\n",
      "Error promedio: 0.0412\n",
      "Precisión = 99.66%.\n",
      "Performance of Mejor Aleatorio\n",
      "Error promedio: 0.0184\n",
      "Precisión = 99.85%.\n",
      "Mejora de 0.19%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels, name):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Performance of {:s}'.format(name))\n",
    "    print('Error promedio: {:0.4f}'.format(np.mean(errors)))\n",
    "    print('Precisión = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X, Y)\n",
    "base_accuracy = evaluate(base_model, X, Y, 'Base')\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X, Y, 'Mejor Aleatorio')\n",
    "\n",
    "print('Mejora de {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejoramos, marginalmente, pero mejoramos. También hay que tomar en cuenta que ambas evaluaciones están hechas sobre los mismos datos que se usaron para entrenar los modelos!!!!\n",
    "\n",
    "Ahora terminemos el proceso de selección de hiperparámetros con una búsqueda exahustiva sobre una malla reducida. Esta malla sólo se mueve un poco alrededor de los parámetros seleccionados en el método aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 100,\n",
       " 'max_features': 15,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 600}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [70, 80, 90, 100],\n",
    "    'max_features': [11, 13, 15],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'min_samples_split': [3, 5, 10],\n",
    "    'n_estimators': [600, 700, 800, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X, Y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teóricamente esta debería ser una refinación de lo que ya obtuvimos. Probémoslo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Grid\n",
      "Error promedio: 0.0069\n",
      "Precisión = 99.94%.\n",
      "Mejora de 0.10%.\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X, Y, 'Grid')\n",
    "\n",
    "print('Mejora de {:0.2f}%.'.format( 100 * (grid_accuracy - random_accuracy) / random_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
