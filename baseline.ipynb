{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresiones\n",
    "\n",
    "Aquí vamos a hacer muchas regresiones para ver qué combinación de ingeniería de variables y método de regresión da mejores resultados.\n",
    "\n",
    "El primer paso es establecer una _línea base_ para comparar. Para esto vamos a utilizar una regresión de [Random Forest](https://en.wikipedia.org/wiki/Random_forest) sobre los datos preprocesados diréctamente, sin más. Lo único extra que vamos a hacer es escalar las variables.\n",
    "\n",
    "Hay varias razones para usar Random Forest como baseline, primero es sabido que es un buen método para evitar el _overfitting_ y segundo y más importante en nuestro caso, nos da una estimación de la importancia relativa de las variables, esto puede resultar importante para informar nuestras desiciones más adelante.\n",
    "\n",
    "En general, una regresión tiene un conjunto de _hiperparámetros_ que deben ajustarse para obtener un modelo específico. Este ajuste se hace buscando soluciones en el espacio de hiperparámetros, para evitar ajustar nuestro modelo demasiado (aumentar el sesgo), vamos a usar _cross validation_.\n",
    "\n",
    "Primero vamos a ver cuáles son los hiperparámetros que queremos ajustar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos los datos\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"data/train_preprocesado.csv\")\n",
    "#por alguna razón quedaron dos Na en BsmtCond, así los quitamos pero en realidad hay que regresar a ver qué pasó\n",
    "df_train.dropna(inplace=True)\n",
    "# creamos dataframes para las variables y el objetivo\n",
    "Y = df_train['SalePrice']\n",
    "X = df_train.drop(['SalePrice','Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros por defecto:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 'warn',\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "print('Parámetros por defecto:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators = número de árboles en el bosque\n",
    "- max_features = máximo número de variables a considerar en cada _split_\n",
    "- max_depth = profundidad máxima para cada árbol\n",
    "- min_samples_split = numero mínimo de datos en un nodo antes de un _split_\n",
    "- min_samples_leaf = número mínimo de datos en un nodo\n",
    "- bootstrap = método para muestrear (con o sin reemplazo)\n",
    "\n",
    "Si lo piensa uno, son un montón de parámetros con un montón de valores posibles, entonces tenemos que encontrar alguna forma eficiente de buscar (en el espacio de hiperparámetros). Ahora lo que vamos a hacer es una búsqueda en dos etapas. primero vamos a definir una _malla_ grande de valores y vamos a buscar a azar dentro de esa malla, eso nos va a reducir el espacio de búsqueda, luego vamos a usar ese espacio reducido para utilizar un método más sofisticado (pero más costoso computacionalmente) de búsqueda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Lista ed valores para el número de estimadores\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# máximo número de variables a considerar en cada _split_\n",
    "max_features = ['auto', 'sqrt']\n",
    "# profundidad máxima para cada árbol\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# numero mínimo de datos en un nodo antes de un _split_\n",
    "min_samples_split = [2, 5, 10]\n",
    "# número mínimo de datos en un nodo\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# método para muestrear (con o sin reemplazo)\n",
    "#bootstrap = [True, False]\n",
    "# Malla aleatoria\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay exáctamente $2 * 12 * 2 * 3 * 3 * 10 = 4320$ combinaciones de variables en nuestra malla. Por eso no las vamos a probar todas, vamos a buscar aleatoriamente. \n",
    "\n",
    "Evidentemente, la búsqueda para encontrar un buen conjunto de hiperparámetros necesita una métrica para medir el desempeño. En sklearn, cada regresor provee metricas de evaluación, el problema es que esa evaluación se hace sobre la muestra completa, es decir, sobre todos los datos que el modelo _ya vió_. Esto representa un problema porque con facilidad vamos a caer en overfitting, es decir, aumentar la _varianza_ del modelo: su sensibilidad a los datos con los que se entrenó. Modelos con alta varianza, tienden a tener errores grandes cuando se les utiliza con datos nuevos.\n",
    "\n",
    "Métodos basados en _bootstraping_ como los Random Forests, proveen una forma natural de eliminar este problema: estimar el error utilizando lo que se llama la muestra _Out of Bag_ (OOB). Este tipo de métodos de ensamble utiliza sólo una porción de los datos para entrenar cada uno de los regresores individuales, de esta forma, al final hay un conjunto de observaciones que no fueron empleadas para entrenar _ningún_ regresor individual, esta muestra (OOB) se puede utilizar para estimar el error sin caer en overfitting. Entonces, vamos a hacer nuestra búsquerda usando el `oob_score`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 20}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un modelo vacío\n",
    "rf = RandomForestRegressor(oob_score=True, bootstrap=True)\n",
    "# Búsqueda aleatoria usando 3-fold CV, \n",
    "# Busca sobre 100 iteraciones \n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Ajusta sobre los datos\n",
    "rf_random.fit(X, Y)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver si la búsqueda aleatoria nos da un mejor modelo que el modelo base (con parámetros por default). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score para el modelo base es: 0.8744\n",
      "El score para el mejor modelo de la búsqueda aleatoria: 0.8759\n",
      "La mejora fue de 0.17%\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 100, random_state = 42, oob_score=True)\n",
    "base_model.fit(X, Y)\n",
    "print('El score para el modelo base es: {:0.4f}'.format(base_model.oob_score_))\n",
    "print('El score para el mejor modelo de la búsqueda aleatoria: {:0.4f}'.format(rf_random.best_estimator_.oob_score_))\n",
    "print('La mejora fue de {:0.2f}%'.format(100 * (rf_random.best_estimator_.oob_score_ - base_model.oob_score_) / base_model.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginalmente pero mejoramos!\n",
    "\n",
    "Ahora vamos a ver si refinando la búsqueda, a partir de los parámetros que ya encontramos, podemos mejorar un poco más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 729 out of 729 | elapsed: 22.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 230,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 800}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [15, 20, 25],\n",
    "    'max_features': [230, 240, 251],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'n_estimators': [800, 800, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(oob_score=True, bootstrap=True)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X, Y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teóricamente esta debería ser una refinación de lo que ya obtuvimos. Probémoslo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score para el modelo refinado es: 0.8762\n",
      "El score para el mejor modelo de la búsqueda aleatoria: 0.8759\n",
      "La mejora fue de 0.03%\n"
     ]
    }
   ],
   "source": [
    "print('El score para el modelo refinado es: {:0.4f}'.format(grid_search.best_estimator_.oob_score_))\n",
    "print('El score para el mejor modelo de la búsqueda aleatoria: {:0.4f}'.format(rf_random.best_estimator_.oob_score_))\n",
    "print('La mejora fue de {:0.2f}%'.format(100 * (grid_search.best_estimator_.oob_score_ - rf_random.best_estimator_.oob_score_) / rf_random.best_estimator_.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno, marginalmente pero seguimos mejorando...\n",
    "\n",
    "Una ventaja de los Random Forests es que nos  pueden dar una medida de la importancia relativa de los parámtetros, grafiquemos estas para el mejor modelo que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcd52def358>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "feat_importances = pd.Series(grid_search.best_estimator_.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizá no tan sorprendentemente la calidad general es la variables más importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Ahora sí tenemos ya nuestro modelo, entonces sometámos los resultados a Kaggle para ver cómo le va. Este es el modelo más simple y el resultado en realidad sólo va a servir como base para comparar los refinamientos que hagamos más adelante.\n",
    "\n",
    "Para hacer la predicción sobre los datos de prueba, vamos a usar el csv con los datos prerpocesados igual que la muestra de entrenamiento y después exportar los resultados en el formato necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/test_preprocesado.csv\")\n",
    "#test_df.drop(['Unnamed: 0.1'], axis=1, inplace=True)\n",
    "#X_test = test_df.drop(['Id'], axis=1)\n",
    "result = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "result_df.columns = ['SalePrice']\n",
    "result_df = result_df.join(test_df['Id'])\n",
    "#result_df.to_csv(\"data/result_base.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>119187.545888</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>147335.347805</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>169191.564164</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>174843.510971</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>193777.908958</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1454</td>\n",
       "      <td>75231.458875</td>\n",
       "      <td>2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455</td>\n",
       "      <td>77768.304761</td>\n",
       "      <td>2916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>157359.329947</td>\n",
       "      <td>2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>107807.366896</td>\n",
       "      <td>2918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1458</td>\n",
       "      <td>227931.223859</td>\n",
       "      <td>2919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SalePrice    Id\n",
       "0     119187.545888  1461\n",
       "1     147335.347805  1462\n",
       "2     169191.564164  1463\n",
       "3     174843.510971  1464\n",
       "4     193777.908958  1465\n",
       "...             ...   ...\n",
       "1454   75231.458875  2915\n",
       "1455   77768.304761  2916\n",
       "1456  157359.329947  2917\n",
       "1457  107807.366896  2918\n",
       "1458  227931.223859  2919\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['SalePrice'] = np.exp(result_df['SalePrice'])\n",
    "result_df.to_csv(\"data/result_base.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"data/result_base.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podríamos querer usar nuestro modelo más adelante, lo vamos a guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/models/baseline_RF.joblib']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(grid_search.best_estimator_, 'data/models/baseline_RF.joblib')\n",
    "\n",
    "# Para usarlo después:\n",
    "# model = load('data/models/baseline_RF.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
